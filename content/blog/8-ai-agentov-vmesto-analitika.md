---
title: "Исследование рынка за ночь: как я перестал делать это руками"
date: 2026-02-25
lastmod: 2026-02-25
description: "Как я построил пайплайн из 8 AI-агентов для автоматизации market research через JTBD framework"
tags: ["ai", "multi-agent", "market-research", "автоматизация"]
slug: "8-ai-agentov-vmesto-analitika"
draft: false
---

Я ненавидел эту часть стартапа больше всего. Анализ конкурентов растягивался на несколько дней, сегментация аудитории превращалась в таблицы с десятками листов - каждый цикл уточнений требовал ещё нескольких часов. Построил пайплайн из 8 AI-агентов. Теперь получаю полный анализ за ночь.

## Я делал исследования сам, потому что не было выбора

Каждый новый проект начинался одинаково: открываешь Google, начинаешь собирать данные о конкурентах - и через три дня понимаешь, что нужно ещё две недели. Я прошёл через это с тремя проектами подряд, прежде чем взялся за автоматизацию.

Построил систему из 8 специализированных AI-агентов. Каждый отвечает за свой участок: file-based handoff, incremental execution, разные модели для разных задач.

Первый пайплайн был на 10 агентов. Система падала в трёх местах: Subsegmenter терял контекст о фичах конкурентов, Analyst галлюцинировал при больших объёмах данных, Strategist генерировал противоречивые рекомендации. Сократил до 8 - количество успешных прогонов без сбоев выросло с примерно одного из пяти до устойчивого большинства.

## Multi-agent система: как она собирается

Researcher берёт brief и превращает его в research questions через JTBD: что клиент реально хочет достичь, кто конкуренты, как продвигаются. Segmenter делит рынок на группы, Subsegmenter ищет нюансы внутри каждой - специфичные боли и мотиваторы подсегментов.

Дальше цепочка: Respondent Generator создаёт синтетических представителей сегментов, Analyst извлекает паттерны через все профили, Scorer приоритизирует по impact, Strategist превращает инсайты в рекомендации, Reporter собирает финальный отчёт.

Я построил beachhead-research - CLI-утилита на TypeScript для market research через JTBD framework.

## 8 агентов в цепочке: от brief до стратегии

**Respondent Generator** создаёт синтетические профили с должностью, индустрией, возрастом, локацией - потом моделирует поведение: что спровоцировало начать искать решение, какие альтернативы рассматривают, что может остановить от покупки.

Экспериментировал с количеством профилей. При малом количестве все попадают в одну категорию - "технический директор B2B SaaS" - и не появляется разброс по контексту покупки. При избыточном профили начинают дублировать друг друга дословно. Нашёл рабочий диапазон опытным путём.

Агенты передают результат через JSON-файлы со строгой схемой: schemaVersion, trace_id, timestamp, validation_status. Если что-то пошло не так на шаге 5 - перезапускаю с шага 5 через `--from-step 5`, не теряя предыдущую работу.

Под капотом - разные модели. Haiku берёт быстрый поиск. Sonnet генерирует профили. Opus работает на стратегии. Полный цикл - 3-4 часа.

## Синтетические профили: моделирование аудитории без людей

На одном проекте профили дали позитивный вердикт фиче: высокая готовность к покупке, убедительные обоснования. Когда проверил на реальных пользователях - большинство сказали "интересно, но мы сейчас это не будем внедрять". Профили не учли friction от интеграции с legacy-системами и политику согласования бюджета. Синтетические пользователи не имеют истории с предыдущими внедрениями, нет руководства, которое уже обожглось на похожем проекте.

Синтетика генерирует гипотезы для проверки. Финальную валидацию всегда делаю с реальными людьми.

## Паттерн виден, причина - нет

Система заметила: все конкуренты в сегменте делают контент-маркетинг. Полезное наблюдение. Но агент не объяснит, почему одни выросли на этом, а другие закрылись - кто попал в нужную волну, а кто опоздал на два года. Это требует понимания контекста, которого нет в данных.

Корреляцию находит хорошо. Механику - нет.

Хороший пайплайн строится на обоих: агент собирает и документирует, человек видит причинно-следственные связи там, где агент видит только паттерны.

## Handoff - это где ломается или работает

Передача контекста между агентами оказалась самым хрупким местом в моей системе. Не оркестрация, не промпты - именно граница между агентами.

Моя система использует file-based handoff: агенты пишут JSON со строгой схемой, следующий читает. Если агент упал - я вижу на каком шаге и какие данные передавались. Без этого система превращается в чёрный ящик.

## Anthropic SDK сделал это возможным

За ночь работы агентов я получаю то, на что раньше уходили недели. Anthropic SDK для работы с агентами дал надёжную оркестрацию - до него приходилось вручную следить за состоянием между вызовами, и это само по себе отнимало время. Стоимость запуска укладывается в диапазон нескольких десятков долларов.

## Как начать (даже без кода)

Открой Claude, опиши свой продукт и попроси проанализировать конкурентов - кто они, что делают, как продвигаются.

Рабочий промпт выглядит так: "Проанализируй пять конкурентов: [список]. Для каждого - основной сегмент, главный канал продвижения, три ключевых сообщения в маркетинге." Получишь структурированную базу для дальнейшей работы. Дальше добавляй web search для трендов и моделирование профилей через prompt engineering.

## AI освобождает, человек направляет

Документирование, суммирование, сбор данных - это теперь не моя работа. Думаю о стратегии, а не провожу дни в таблицах с десятками листов.

Incremental execution с `--from-step N`, file-based handoff между агентами, разные модели для разных задач. Всё работает.
