---
title: "Зачем я установил Exa MCP в Claude Code и больше не использую WebFetch"
date: 2026-02-24
lastmod: 2026-02-24
description: "Почему встроенный WebFetch не справляется с API-документацией, как Exa MCP решает проблему и что это даёт на практике"
tags: ["claude-code", "mcp", "exa", "tools"]
slug: "exa-mcp-vs-webfetch-claude-code"
draft: false
---

Месяц назад разбирался с документацией Stripe API. Вернулся размытый кусок текста - без параметров, без схем, без типов. Пришлось открывать браузер самому. Просто бесполезно.

## Что не так с WebFetch

Внутри всё работает так: запрос уходит в Haiku вместе с промптом, Haiku делает резюме страницы, агент получает этот пересказ. Не сырой HTML, не markdown - именно пересказ. Быстрая проверка "существует ли такая функция" - ладно, хватает. Для API-документации - катастрофа.

Реальные схемы запросов просто не видны. Пишутся вызовы, которые выглядят правдоподобно, но падают при первом запуске - параметры угаданы, а не прочитаны. OAuth-защищённые ресурсы возвращают 401. Всегда. Это официальная позиция Anthropic: "OAuth authentication is currently not supported", зафиксировано в трёх отдельных issues в репо claude-code.

Stripe - хороший пример. На запрос "create payment intent API" WebFetch выдаёт что-то вроде: "Stripe Payment Intent создаётся через POST запрос, принимает сумму и валюту." Без `amount`, без `currency`, без `payment_method_types`. Exa MCP возвращает полный блок документации с параметрами, типами, схемой объекта ответа, примером кода. Структура видна - и код пишется правильно.

Но дальше было ещё интереснее. Запросил полный workflow создания PaymentIntent: сначала создать Customer, потом прикрепить PaymentMethod, потом создать Intent с `confirm: true`. Через WebFetch каждый шаг был угадан. Через `get_code_context_exa` пришёл реальный пример из production-репозитория: с обработкой `requires_action`, с 3DS редиректом, с вебхуком на `payment_intent.succeeded`. Не описание процесса, а рабочий код.

## Установка

Одна команда:

```bash
claude mcp add --transport http exa https://mcp.exa.ai/mcp
```

Без API ключа работает сразу. Бесплатный план покрывает первые эксперименты. Ключ нужен только когда упираешься в rate limits - добавляешь `?exaApiKey=YOUR_KEY` к URL и продолжаешь.

## Три инструмента

После установки доступны три инструмента: `web_search_exa` для обычного поиска, `get_code_context_exa` для кода, `company_research_exa` для бизнес-данных.

Главная звезда - `get_code_context_exa`. Поиск ведётся по миллиардам репозиториев GitHub, по Stack Overflow, по официальным документациям. Результат оптимизирован под контекстное окно: функция не обрезается посередине, комментарии сохраняются, импорты на месте.

Попробовал сразу после установки. Нужны были примеры SQLAlchemy async sessions. WebFetch выдал шаблон с landing page - общий, без деталей. Из репозитория пришёл код: с обработкой исключений, с контекстным менеджером, с комментарием "не используй `create_engine` вместо `create_async_engine`". Разница в качестве - не на проценты.

## Что говорит бенчмарк

По точности в SimpleQA - стандартном бенчмарке от OpenAI - Exa показала высокие результаты среди search API для RAG-приложений, конкурируя с Perplexity Sonar-Pro и Bing. Для меня это важно: меньше галлюцинаций в ответах напрямую связано с качеством контекста, который получает модель.

## Реальный случай - BrainGrid

Команда BrainGrid строила агента для интеграции со Stripe. Claude с WebFetch возвращал "зашифрованный блок" - параметры, типы, схемы нечитаемы. Сломанные реализации, придуманные API-вызовы. Перешли на Exa MCP. Вся реализация заняла меньше 100 строк на Vercel AI SDK. Читать документацию стало возможным - выдумывать её перестало быть нужным.

## Ежедневное использование

Два сценария, где это работает каждый день.

Первый - незнакомые библиотеки. Недавно разбирался с Resend email API. `get_code_context_exa` сразу нашёл пример с правильными заголовками, обработкой ошибок, структурой ответа. Рабочий код, не описание с лендинга.

Второй - отладка странных ошибок. Когда модель застряла на "cannot read property of undefined in prisma transaction", `web_search_exa` нашёл конкретный Stack Overflow тред с решением - полный текст, все комментарии, принятый ответ. WebFetch дал бы пересказ.

## Честные ограничения

Есть минусы, о которых стоит знать. MCP-инструменты потребляют много токенов контекстного окна - по некоторым оценкам, до 66 000 токенов до начала разговора. Это треть окна Sonnet. Лучше активировать только нужные инструменты через `?tools=get_code_context_exa`, а не все сразу. Ещё не все сайты индексируются - узкоспециализированные внутренние документации или свежие блог-посты могут отсутствовать. livecrawl решает проблему свежести, но увеличивает задержку.

## Сравнение

| | WebFetch | Exa MCP |
|---|---|---|
| Доступ к контенту | Только резюме от Haiku | Полный текст, markdown |
| OAuth ресурсы | 401 ошибки | Через инфраструктуру Exa |
| Кэш | 15 минут | livecrawl для свежих данных |
| Код и примеры | Нет специализации | `get_code_context_exa` |

## Когда WebFetch достаточно

Честно: не всегда нужен Exa. Проверить существует ли параметр `idempotency_key` в SDK - WebFetch справится. Быстрая навигационная проверка, не требующая структурированных данных - разницы нет.

Exa нужен когда модель должна понять структуру, а не получить описание.

## Цена

$5 за тысячу запросов. При обычной разработке это не набегает быстро - несколько запросов за сессию, не тысячи. Начни бесплатно, добавь ключ когда почувствуешь лимиты.

Команда выше. Пять минут - и проверишь сам.
